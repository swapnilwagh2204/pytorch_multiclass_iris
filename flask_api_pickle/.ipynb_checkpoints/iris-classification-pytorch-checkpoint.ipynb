{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "12442d691ca5f635b2c48d9f9462f1fa2098cc1a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d5f0079b1d8e90e4393cb22544604b00d6ad995e"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,50)\n",
    "        self.layer2 = nn.Linear(50, 20)\n",
    "        self.layer3 = nn.Linear(20, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x)) # To check with the loss function\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "3099490f7cf6f9c178842d3d042f9e8173207b7a"
   },
   "outputs": [],
   "source": [
    "features, labels = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "aec1515e7029db5699bdcaa12a2cf4e7eb0dc9cb"
   },
   "outputs": [],
   "source": [
    "features_train,features_test, labels_train, labels_test = train_test_split(features, labels, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0130b6fa11a2fac5e479d0bc0d45b93b2b54f8bf"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "model = Model(features_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "\n",
    "def print_(loss):\n",
    "    print (\"The loss calculated: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "da7c6763488c302a632a6d2474cc69de4dcc611d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-584eef3233bb>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x)) # To check with the loss function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss calculated:  1.0885374546051025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swapnil/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 2\n",
      "The loss calculated:  1.0677402019500732\n",
      "Epoch # 3\n",
      "The loss calculated:  1.0483728647232056\n",
      "Epoch # 4\n",
      "The loss calculated:  1.026077151298523\n",
      "Epoch # 5\n",
      "The loss calculated:  0.9984601736068726\n",
      "Epoch # 6\n",
      "The loss calculated:  0.9661648869514465\n",
      "Epoch # 7\n",
      "The loss calculated:  0.9317272305488586\n",
      "Epoch # 8\n",
      "The loss calculated:  0.9025782942771912\n",
      "Epoch # 9\n",
      "The loss calculated:  0.8782986402511597\n",
      "Epoch # 10\n",
      "The loss calculated:  0.8563094139099121\n",
      "Epoch # 11\n",
      "The loss calculated:  0.8378043174743652\n",
      "Epoch # 12\n",
      "The loss calculated:  0.8201760649681091\n",
      "Epoch # 13\n",
      "The loss calculated:  0.8052523732185364\n",
      "Epoch # 14\n",
      "The loss calculated:  0.7943262457847595\n",
      "Epoch # 15\n",
      "The loss calculated:  0.780354380607605\n",
      "Epoch # 16\n",
      "The loss calculated:  0.7649027705192566\n",
      "Epoch # 17\n",
      "The loss calculated:  0.7518129944801331\n",
      "Epoch # 18\n",
      "The loss calculated:  0.7356283068656921\n",
      "Epoch # 19\n",
      "The loss calculated:  0.7206076979637146\n",
      "Epoch # 20\n",
      "The loss calculated:  0.7070395350456238\n",
      "Epoch # 21\n",
      "The loss calculated:  0.6909991502761841\n",
      "Epoch # 22\n",
      "The loss calculated:  0.67909175157547\n",
      "Epoch # 23\n",
      "The loss calculated:  0.6647579073905945\n",
      "Epoch # 24\n",
      "The loss calculated:  0.6551461219787598\n",
      "Epoch # 25\n",
      "The loss calculated:  0.6432651281356812\n",
      "Epoch # 26\n",
      "The loss calculated:  0.6355332136154175\n",
      "Epoch # 27\n",
      "The loss calculated:  0.6265664100646973\n",
      "Epoch # 28\n",
      "The loss calculated:  0.6204758882522583\n",
      "Epoch # 29\n",
      "The loss calculated:  0.6138246655464172\n",
      "Epoch # 30\n",
      "The loss calculated:  0.6088848114013672\n",
      "Epoch # 31\n",
      "The loss calculated:  0.6047631502151489\n",
      "Epoch # 32\n",
      "The loss calculated:  0.6010032296180725\n",
      "Epoch # 33\n",
      "The loss calculated:  0.5982586145401001\n",
      "Epoch # 34\n",
      "The loss calculated:  0.595308244228363\n",
      "Epoch # 35\n",
      "The loss calculated:  0.593421459197998\n",
      "Epoch # 36\n",
      "The loss calculated:  0.5910924673080444\n",
      "Epoch # 37\n",
      "The loss calculated:  0.5897703170776367\n",
      "Epoch # 38\n",
      "The loss calculated:  0.5879980325698853\n",
      "Epoch # 39\n",
      "The loss calculated:  0.5870799422264099\n",
      "Epoch # 40\n",
      "The loss calculated:  0.5856904983520508\n",
      "Epoch # 41\n",
      "The loss calculated:  0.5850065350532532\n",
      "Epoch # 42\n",
      "The loss calculated:  0.5839095711708069\n",
      "Epoch # 43\n",
      "The loss calculated:  0.5833979249000549\n",
      "Epoch # 44\n",
      "The loss calculated:  0.5825174450874329\n",
      "Epoch # 45\n",
      "The loss calculated:  0.582119882106781\n",
      "Epoch # 46\n",
      "The loss calculated:  0.58140629529953\n",
      "Epoch # 47\n",
      "The loss calculated:  0.5811041593551636\n",
      "Epoch # 48\n",
      "The loss calculated:  0.5805130004882812\n",
      "Epoch # 49\n",
      "The loss calculated:  0.5802662968635559\n",
      "Epoch # 50\n",
      "The loss calculated:  0.5797910094261169\n",
      "Epoch # 51\n",
      "The loss calculated:  0.5795835852622986\n",
      "Epoch # 52\n",
      "The loss calculated:  0.5791835784912109\n",
      "Epoch # 53\n",
      "The loss calculated:  0.5790141224861145\n",
      "Epoch # 54\n",
      "The loss calculated:  0.5786932110786438\n",
      "Epoch # 55\n",
      "The loss calculated:  0.5785232186317444\n",
      "Epoch # 56\n",
      "The loss calculated:  0.5782425999641418\n",
      "Epoch # 57\n",
      "The loss calculated:  0.578095018863678\n",
      "Epoch # 58\n",
      "The loss calculated:  0.5779072046279907\n",
      "Epoch # 59\n",
      "The loss calculated:  0.5777500867843628\n",
      "Epoch # 60\n",
      "The loss calculated:  0.5775905847549438\n",
      "Epoch # 61\n",
      "The loss calculated:  0.5774176716804504\n",
      "Epoch # 62\n",
      "The loss calculated:  0.5772809386253357\n",
      "Epoch # 63\n",
      "The loss calculated:  0.5771260857582092\n",
      "Epoch # 64\n",
      "The loss calculated:  0.5770329833030701\n",
      "Epoch # 65\n",
      "The loss calculated:  0.576897919178009\n",
      "Epoch # 66\n",
      "The loss calculated:  0.57679682970047\n",
      "Epoch # 67\n",
      "The loss calculated:  0.5766598582267761\n",
      "Epoch # 68\n",
      "The loss calculated:  0.5765662789344788\n",
      "Epoch # 69\n",
      "The loss calculated:  0.576474666595459\n",
      "Epoch # 70\n",
      "The loss calculated:  0.5763826966285706\n",
      "Epoch # 71\n",
      "The loss calculated:  0.5762889981269836\n",
      "Epoch # 72\n",
      "The loss calculated:  0.5761812329292297\n",
      "Epoch # 73\n",
      "The loss calculated:  0.5761178135871887\n",
      "Epoch # 74\n",
      "The loss calculated:  0.5760365128517151\n",
      "Epoch # 75\n",
      "The loss calculated:  0.5759641528129578\n",
      "Epoch # 76\n",
      "The loss calculated:  0.5758762955665588\n",
      "Epoch # 77\n",
      "The loss calculated:  0.5757929086685181\n",
      "Epoch # 78\n",
      "The loss calculated:  0.5757289528846741\n",
      "Epoch # 79\n",
      "The loss calculated:  0.5756557583808899\n",
      "Epoch # 80\n",
      "The loss calculated:  0.5755886435508728\n",
      "Epoch # 81\n",
      "The loss calculated:  0.575519859790802\n",
      "Epoch # 82\n",
      "The loss calculated:  0.5754566192626953\n",
      "Epoch # 83\n",
      "The loss calculated:  0.5753912329673767\n",
      "Epoch # 84\n",
      "The loss calculated:  0.5753397941589355\n",
      "Epoch # 85\n",
      "The loss calculated:  0.5752862095832825\n",
      "Epoch # 86\n",
      "The loss calculated:  0.5752280950546265\n",
      "Epoch # 87\n",
      "The loss calculated:  0.5751661062240601\n",
      "Epoch # 88\n",
      "The loss calculated:  0.5751010179519653\n",
      "Epoch # 89\n",
      "The loss calculated:  0.575050950050354\n",
      "Epoch # 90\n",
      "The loss calculated:  0.5750035047531128\n",
      "Epoch # 91\n",
      "The loss calculated:  0.5749474167823792\n",
      "Epoch # 92\n",
      "The loss calculated:  0.5748841166496277\n",
      "Epoch # 93\n",
      "The loss calculated:  0.5748365521430969\n",
      "Epoch # 94\n",
      "The loss calculated:  0.5747920870780945\n",
      "Epoch # 95\n",
      "The loss calculated:  0.5747438669204712\n",
      "Epoch # 96\n",
      "The loss calculated:  0.57469242811203\n",
      "Epoch # 97\n",
      "The loss calculated:  0.5746386647224426\n",
      "Epoch # 98\n",
      "The loss calculated:  0.5745834112167358\n",
      "Epoch # 99\n",
      "The loss calculated:  0.5745379328727722\n",
      "Epoch # 100\n",
      "The loss calculated:  0.5744954347610474\n"
     ]
    }
   ],
   "source": [
    "# Not using dataloader\n",
    "x_train, y_train = Variable(torch.from_numpy(features_train)).float(), Variable(torch.from_numpy(labels_train)).long()\n",
    "for epoch in range(1, epochs+1):\n",
    "    print (\"Epoch #\",epoch)\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print_(loss.item())\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # Gradients\n",
    "    optimizer.step() # Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1ec65ca8010cf263f6c2a572c74b9f573d769548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-584eef3233bb>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer3(x)) # To check with the loss function\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "pred = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "4b830cef57e1738d85bc7c9934aa990ecbdbafaf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "241f264bf786bdbeee774f099153b2b2e6e2c128"
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "a8494c79d4118a4a6d64390d5795fa5ab663be7e"
   },
   "outputs": [],
   "source": [
    "print (\"The accuracy is\", accuracy_score(labels_test, np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "c14512ad13743b21418bff6579263cf2d11234e1"
   },
   "outputs": [],
   "source": [
    "# Checking for first value\n",
    "np.argmax(model(x_test[0]).detach().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "bbe2250f5114f2384f3b452cc42e97ee0fa3d868"
   },
   "outputs": [],
   "source": [
    "labels_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "6c9a2e66f5737f59b9850406643e88570f294be1"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"iris-pytorch.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "5dfa3c0872996b78b31a721fb8d397d5e70c29c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model = torch.load(\"iris-pytorch.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "09155770eb48db3e2834d0e78e992cc67015b748"
   },
   "outputs": [],
   "source": [
    "np.argmax(saved_model(x_test[0]).detach().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb2efc974e634e32c0fce8b53938d06136815d1b",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
